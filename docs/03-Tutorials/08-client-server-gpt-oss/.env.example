# Local LLM Configuration
LLM_PROVIDER=ollama  # Options: ollama, transformers
MODEL_NAME=smollm:135m  # For Ollama: lightweight and fast model
# MODEL_NAME=google/flan-t5-base  # For Transformers - better for conversations

# Ollama Configuration (if using Ollama)
OLLAMA_HOST=http://localhost:11434

# Server Configuration
STORAGE_MCP_SERVER_URL=http://localhost:8000/sse
SERVER_HOST=0.0.0.0
SERVER_PORT=8000

# Database
DATABASE_PATH=./tasks.db
